# -*- coding: utf-8 -*-
"""RNN_batch_size_variation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uOvWrtITd3PYQWaTexawKdgZZiEM4mjn
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, SimpleRNN

mnist = tf.keras.datasets.mnist
(x, y),(x_test, y_test) = mnist.load_data()

##Adding the preprocessing Unit
#Extracting validation set normalizing the data
x_train = (x[:50000])/255.0
x_val = (x[50000:])/255.0
y_train = y[:50000]
y_val = y[50000:]
# print(x_train.shape)
# print(y_train.shape)
# print(x_val.shape)
# print(y_val.shape)
# print(x_train[0])
num_classes = 10
y_train = to_categorical(y_train, num_classes)
y_val = to_categorical(y_val, num_classes)
y_test = to_categorical(y_test, num_classes)

##setiing the parameters
epochs = 15
lr = 0.01
decay = 1e-5
batch_sizes=[1,128]

fig, axes = plt.subplots(nrows=1, ncols=2, figsize = (25,5))
for batch_size in batch_sizes:
  model = Sequential()
  model.add(SimpleRNN(128, input_shape= (x_train.shape[1:]), activation='relu', return_sequences=True))
  model.add(SimpleRNN(128, activation='relu'))

  model.add(Dense(10, activation='softmax'))

  sgd = tf.keras.optimizers.SGD()

  model.compile(loss='mean_squared_error', optimizer = sgd, metrics=['accuracy'])
  history_lstm = model.fit(x_train, y_train, epochs=epochs, verbose=0, batch_size = batch_size, validation_data=(x_val, y_val))
  Accuracy_validation = history_lstm.history['val_acc']
  Accuracy_training = history_lstm.history['acc']
  test_accuracy = model.evaluate(x_test, y_test)
  print("The testing accuracy metric for %s batch_size is %s" % (batch_size, test_accuracy))
  print("---------------------------------------------------")
  axes[0].plot(np.arange(1,epochs+1),Accuracy_validation,label="batch_size=%s"%(batch_size))
  axes[1].plot(np.arange(1,epochs+1),Accuracy_training,label="batch_size=%s"%(batch_size))
axes[0].grid(True)
axes[0].set_xlabel("--- Epochs --->")
axes[0].set_ylabel("--- Validation Accuracy --->")
axes[0].legend()

axes[1].grid(True)
axes[1].set_xlabel("--- Epochs --->")
axes[1].set_ylabel("--- Training Accuracy --->")
axes[1].legend()

